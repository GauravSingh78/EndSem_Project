{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (2100000, 5)\n",
      "Shape of y: (2100000,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = r\"C:\\Users\\Admin\\Desktop\\forthSem\\train\"\n",
    "\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        data = pd.read_csv(file_path)\n",
    "        \n",
    "        X_file = data[['vdd','pd', 'vinp','temperature','process']] \n",
    "        y_file = data['vinn']\n",
    "        \n",
    "        X_data.append(X_file)\n",
    "        y_data.append(y_file)\n",
    "\n",
    "X = pd.concat(X_data, ignore_index=True)\n",
    "y = pd.concat(y_data, ignore_index=True)\n",
    "\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vdd</th>\n",
       "      <th>pd</th>\n",
       "      <th>vinp</th>\n",
       "      <th>temperature</th>\n",
       "      <th>process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15</td>\n",
       "      <td>fastnfastp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15</td>\n",
       "      <td>fastnfastp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15</td>\n",
       "      <td>fastnfastp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15</td>\n",
       "      <td>fastnfastp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15</td>\n",
       "      <td>fastnfastp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099995</th>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>1.638227</td>\n",
       "      <td>85</td>\n",
       "      <td>typical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099996</th>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>1.640581</td>\n",
       "      <td>85</td>\n",
       "      <td>typical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099997</th>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>1.642936</td>\n",
       "      <td>85</td>\n",
       "      <td>typical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099998</th>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>1.645291</td>\n",
       "      <td>85</td>\n",
       "      <td>typical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099999</th>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>1.647645</td>\n",
       "      <td>85</td>\n",
       "      <td>typical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2100000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            vdd      pd      vinp  temperature     process\n",
       "0        0.0000  0.0000  0.000000          -15  fastnfastp\n",
       "1        0.0033  0.0033  0.000000          -15  fastnfastp\n",
       "2        0.0066  0.0066  0.000000          -15  fastnfastp\n",
       "3        0.0099  0.0099  0.000000          -15  fastnfastp\n",
       "4        0.0132  0.0132  0.000000          -15  fastnfastp\n",
       "...         ...     ...       ...          ...         ...\n",
       "2099995  3.0000  3.0000  1.638227           85     typical\n",
       "2099996  3.0000  3.0000  1.640581           85     typical\n",
       "2099997  3.0000  3.0000  1.642936           85     typical\n",
       "2099998  3.0000  3.0000  1.645291           85     typical\n",
       "2099999  3.0000  3.0000  1.647645           85     typical\n",
       "\n",
       "[2100000 rows x 5 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X= data[['vdd','pd', 'vinp','temperature','process']]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0.000000\n",
       "1          0.001346\n",
       "2          0.002692\n",
       "3          0.004038\n",
       "4          0.005384\n",
       "             ...   \n",
       "2099995    0.883872\n",
       "2099996    0.883918\n",
       "2099997    0.883964\n",
       "2099998    0.884009\n",
       "2099999    0.884055\n",
       "Name: vinn, Length: 2100000, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = data['vinn']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling Dense.call().\n\n\u001b[1mmodule 'keras.src.backend' has no attribute 'floatx'\u001b[0m\n\nArguments received by Dense.call():\n  • inputs=tf.Tensor(shape=(32, 5), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     42\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\common\\dtypes.py:237\u001b[0m, in \u001b[0;36m_lattice_result_type\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    234\u001b[0m     out_weak_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(out_dtype \u001b[38;5;129;01mis\u001b[39;00m t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m WEAK_TYPES)\n\u001b[0;32m    236\u001b[0m out_weak_type \u001b[38;5;241m=\u001b[39m (out_dtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m out_weak_type\n\u001b[1;32m--> 237\u001b[0m precision \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloatx\u001b[49m()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_weak_type:\n\u001b[0;32m    239\u001b[0m     out_dtype \u001b[38;5;241m=\u001b[39m _resolve_weak_type(out_dtype, precision\u001b[38;5;241m=\u001b[39mprecision)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Exception encountered when calling Dense.call().\n\n\u001b[1mmodule 'keras.src.backend' has no attribute 'floatx'\u001b[0m\n\nArguments received by Dense.call():\n  • inputs=tf.Tensor(shape=(32, 5), dtype=float32)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# Perform label encoding for the 'process' column\n",
    "label_encoder = LabelEncoder()\n",
    "X['process'] = label_encoder.fit_transform(X['process'])\n",
    "\n",
    "\n",
    "# Convert DataFrame to numpy array\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "# Convert data type to float32\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.float32)\n",
    "\n",
    "# Preprocess the input features (if necessary)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import  LabelEncoder\n",
    "\n",
    "label_encoder =LabelEncoder()\n",
    "\n",
    "X.loc[:, 'process'] = label_encoder.fit_transform(X['process'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = X.values.astype(np.float32)\n",
    "y = y.values.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py:855\u001b[0m, in \u001b[0;36mTrainer._pythonify_logs\u001b[1;34m(self, logs)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pythonify_logs\u001b[39m(\u001b[38;5;28mself\u001b[39m, logs):\n\u001b[0;32m    854\u001b[0m     result \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 855\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m()):\n\u001b[0;32m    856\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    857\u001b[0m             result\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(value))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define checkpoint to save the best model\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_scaled, y, validation_data=(X_test_scaled, y_test), epochs=50, batch_size=32, callbacks=[checkpoint])\n",
    "\n",
    "# Load the best model from the checkpoint\n",
    "best_model = load_model('best_model.h5')\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 5\n",
      "Results: [[0.768, 0.768, 0.768, 0.765, 0.767, 0.767, 0.767, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.767], [0.768, 0.768, 0.768, 0.765, 0.767, 0.767, 0.767, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.767], [0.768, 0.768, 0.768, 0.765, 0.767, 0.767, 0.767, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.767], [0.768, 0.768, 0.768, 0.765, 0.767, 0.767, 0.767, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.767], [0.768, 0.768, 0.768, 0.765, 0.767, 0.767, 0.767, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.767]]\n",
      "Average: 0.7676499999999998\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import concurrent.futures\n",
    "\n",
    "def import_set(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        my_set = pickle.load(file)\n",
    "    return my_set\n",
    "\n",
    "def evaluate_function(function_code, kwargs):\n",
    "    exec(function_code)\n",
    "    results = []\n",
    "    for i in range(1, 21):\n",
    "        function_name = f\"decision_tree_rule_{i}\"\n",
    "        function = locals()[function_name]\n",
    "        result = function(**kwargs) or 0\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "def evaluate_all_conditions_parallel(input_parameters, function_code):\n",
    "    results = []\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        future_to_param = {executor.submit(evaluate_function, function_code, params): params for params in input_parameters}\n",
    "        for future in concurrent.futures.as_completed(future_to_param):\n",
    "            params = future_to_param[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "            except Exception as exc:\n",
    "                print(f\"Function execution generated an exception: {exc}\")\n",
    "                results.append([])  # Append empty list as placeholder for failed execution\n",
    "    return results\n",
    "\n",
    "import_file_path = r'exported_set.pkl'\n",
    "function_file_path = r\"TreeFunction.py\"\n",
    "\n",
    "input_parameters = import_set(import_file_path)\n",
    "vinp_value = 1.638227 \n",
    "pd_value = 3.0\n",
    "vdd_value = 3.0\n",
    "process_value = 3\n",
    "temperature_value = 85\n",
    "input_values = {'vinp': vinp_value, 'pd': pd_value, 'vdd': vdd_value, 'process': process_value, 'temperature': temperature_value}\n",
    "\n",
    "with open(function_file_path, 'r') as file:\n",
    "    functions_code = file.read()\n",
    "\n",
    "# Convert input_parameters to a list of dictionaries\n",
    "input_parameters_list = [input_values] * len(input_parameters)\n",
    "\n",
    "result_list = evaluate_all_conditions_parallel(input_parameters_list, functions_code)\n",
    "\n",
    "print(\"Length:\", len(result_list))\n",
    "print(\"Results:\", result_list)\n",
    "print(\"Average:\", np.nanmean(result_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Set: {'pd', 'process', 'vdd', 'vinp', 'temperature'}\n",
      "Length: 20\n",
      "Results: [0.768, 0.768, 0.768, 0.765, 0.767, 0.767, 0.767, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768, 0.767]\n",
      "Average: 0.76765\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def import_set(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        my_set = pickle.load(file)\n",
    "    return my_set\n",
    "\n",
    "import_file_path = r'exported_set.pkl'\n",
    "\n",
    "\n",
    "def evaluate_all_conditions(**kwargs):\n",
    "    results = []\n",
    "\n",
    "    function_file_path = r\"TreeFunction.py\"\n",
    "\n",
    "    with open(function_file_path, 'r') as file:\n",
    "        functions_code = file.read()\n",
    "\n",
    "    for i in range(1,21):\n",
    "        function_name = f\"decision_tree_rule_{i}\"\n",
    "        exec(functions_code)\n",
    "        function = locals()[function_name]\n",
    "        result = function(**kwargs) or 0\n",
    "        results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "input_parameters = import_set(import_file_path)\n",
    "\n",
    "print(\"Imported Set:\", input_parameters)\n",
    "\n",
    "vinp_value = 1.638227 \n",
    "pd_value = 3.0\n",
    "vdd_value = 3.0\n",
    "process_value = 3\n",
    "temperature_value = 85\n",
    "input_values = {'vinp': vinp_value, 'pd': pd_value, 'vdd': vdd_value, 'process':process_value,'temperature':temperature_value}\n",
    "\n",
    "result_list = evaluate_all_conditions(**input_values)\n",
    "\n",
    "print(\"Length:\", len(result_list))\n",
    "print(\"Results:\", result_list)\n",
    "print(\"Average:\", np.average(result_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
