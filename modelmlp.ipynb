{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796b9242-cb59-4af9-9a72-ffb529b6b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"C:\\Users\\Public\\Documents\\title\\concatenate_140.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1708f7-fb06-4af1-a0f6-c66321450b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= pd.get_dummies(df, columns = ['process'])\n",
    "df_train = df_train.replace({True:1, False:0})\n",
    "df_train.to_csv(\"one_forty_train_onehotencoded.csv\")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d8002-af10-4a97-adb5-e6c5c5c5fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ea0ab6-6fca-40c2-a961-5f05915eb1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"one_forty_train_onehotencoded.csv\"\n",
    "df = pd.read_csv(file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f689e334-ac1c-47c8-bf29-674adca65c9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "#print (df.head())\n",
    "inputs = ['vinp','xpd','vdd','temperature','process_fastnfastp','process_fastnslowp','process_slownfastp','process_slownslowp','process_typical','vinn']\n",
    "\n",
    "df_train = df[inputs]\n",
    "print(df_train.columns)\n",
    "print(\"total rows \",df_train.count)\n",
    "\n",
    "\n",
    "df_train1 = pd.DataFrame()\n",
    "df_train1 = df_train[inputs]\n",
    "print (df_train1.columns)\n",
    "print (df_train1.head())\n",
    "\n",
    "\n",
    "X = df_train1.drop('vinn',axis =1).values\n",
    "y = df_train1['vinn'].values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='Adam',loss='mse')\n",
    "\n",
    "model.fit(x=X_train,y=y_train,\n",
    "          validation_data=(X_test,y_test),\n",
    "          batch_size=128,epochs=20)\n",
    "model.summary()\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "model.save(\"neuron_model.h5\")\n",
    "print (\"model saved\")\n",
    "\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('VarScore:',metrics.explained_variance_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7de32ff9-5f8e-4b94-98cf-8d063066144a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 237ms/step\n",
      "[[0.89934444]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# model = load_model('neuron_model.h5')\n",
    "# Load the saved model\n",
    "model = load_model(\"neuron_model.h5\")\n",
    "arr =np.array([[1.647645 , 0.0 , 3.0000, 85, 0, 0, 0, 0, 1]])\n",
    "# arr =np.array([[1.638227   , 0.0 , 3.0000, 85, 0, 0, 0, 0, 1]])\n",
    "# arr =  np.array([[0.0, 0.0, 0.0066, -15, 1, 0, 0, 0, 0]])\n",
    "# arr = np.array([[ 0.,    0.,    3.6, 125.,    0.,    0.,    0.,    1.,   0.]])\n",
    "# arr = np.array([[1.60534539, 3.6, 3.6, 125., 1., 0., 0., 0., 0.]])\n",
    "print(model.predict(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f521feb3-8dbe-4685-b4e7-fac19484ce94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1890000, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ee1ec1-37bb-44f4-8e59-ddf4d3c596a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X_train:\n",
    "    print(i)\n",
    "    print(\"Next line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaef5f0b-32b8-4745-a627-ac06314830e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8a7d22-f9c6-45b0-8993-a396a1da2131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a6c18-082e-4630-a11b-b6c492cbe200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbb4156-d755-416d-b9fc-786b6851fe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "model.fit(x=X_train, y=y_train,\n",
    "          validation_data=(X_test, y_test),\n",
    "          batch_size=128, epochs=10)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Save the model in HDF5 format\n",
    "model.save(\"neuron_model.h5\")\n",
    "\n",
    "print(\"Model saved as 'neuron_model.h5'\")\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('VarScore:', metrics.explained_variance_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5b1ea2-41a0-4a62-9101-ef0d108d8c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Load the model from HDF5 file\n",
    "with h5py.File('neuron_model.h5', 'r') as f:\n",
    "    weights = []\n",
    "    for layer_name in f['model_weights']:\n",
    "        # Access the layer group\n",
    "        layer_group = f['model_weights'][layer_name]\n",
    "        # Extract the weights and biases for this layer\n",
    "        layer_weights = [layer_group['kernel:0'][:], layer_group['bias:0'][:]]\n",
    "        weights.append(layer_weights)\n",
    "        \n",
    "# Define activation functions\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Define function to perform forward propagation\n",
    "def forward_propagation(inputs, weights):\n",
    "    layer_input = inputs\n",
    "    for weight in weights:\n",
    "        layer_output = np.dot(layer_input, weight[0].value) + weight[1].value\n",
    "        layer_input = relu(layer_output)\n",
    "    return layer_output\n",
    "\n",
    "# Example input data (modify this according to your actual data)\n",
    "input_data = np.array([[0.0, 0.0, 0.0066, -15, 1,0,0, 0, 0], [0.0, 0.0, 0.0132, -15, 1,0,0, 0, 0]])\n",
    "\n",
    "# Perform predictions\n",
    "predictions = forward_propagation(input_data, weights)\n",
    "\n",
    "# Print predictions\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c14ee24-8a3a-4f49-8ea9-a53513ecf5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a6dabc-d258-4305-867a-02db32d7a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "# Load data\n",
    "file = \"one_forty_train_onehotencoded.csv\"\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Define input features and target\n",
    "inputs = ['vinp','xpd','vdd','temperature','process_fastnfastp','process_fastnslowp','process_slownfastp','process_slownslowp','process_typical','vinn']\n",
    "df_train = df[inputs]\n",
    "X = df_train.drop('vinn', axis=1).values\n",
    "y = df_train['vinn'].values\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "# Normalize input features\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=128, epochs=10, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Save the model in HDF5 format\n",
    "model.save(\"neuron_model.h5\")\n",
    "print(\"Model saved as 'neuron_model.h5'\")\n",
    "\n",
    "# Evaluate the model performance\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('VarScore:', metrics.explained_variance_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7964cab9-b093-4cae-93d0-afdbab6b547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Load the model from HDF5 file\n",
    "with h5py.File('neuron_model.h5', 'r') as f:\n",
    "    weights = []\n",
    "    for layer in f['model_weights']:\n",
    "        layer_group = f['model_weights'][layer]\n",
    "        layer_weights = [layer_group[param][()] for param in layer_group]\n",
    "        weights.append(layer_weights)\n",
    "\n",
    "# Define activation functions\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Define function to perform forward propagation\n",
    "def forward_propagation(inputs, weights):\n",
    "    layer_input = inputs\n",
    "    for weight_set in weights:\n",
    "        layer_output = np.dot(layer_input, weight_set[0].T) + weight_set[1]  # Transpose the weight matrix for correct matrix multiplication\n",
    "        layer_input = relu(layer_output)\n",
    "    return layer_output\n",
    "\n",
    "# Example input data (modify this according to your actual data)\n",
    "input_data = np.array([[0.0, 0.0, 0.0066, -15, 1, 0, 0, 0, 0]])\n",
    "\n",
    "# Perform predictions\n",
    "predictions = forward_propagation(input_data, weights)\n",
    "\n",
    "# Print predictions\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d795854-904f-4f4c-9854-95dde3f97131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6243807a-c7b7-4e4f-b4a6-1ea81e6eca97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b63b9c4-ee5a-410e-9307-4415e9265a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import h5py\n",
    "\n",
    "file = \"one_forty_train_onehotencoded.csv\"\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "\n",
    "#print (df.head())\n",
    "inputs = ['vinp','xpd','vdd','temperature','process_fastnfastp','process_fastnslowp','process_slownfastp','process_slownslowp','process_typical','vinn']\n",
    "\n",
    "df_train = df[inputs]\n",
    "print(df_train.columns)\n",
    "print(\"total rows \",df_train.count)\n",
    "\n",
    "\n",
    "df_train1 = pd.DataFrame()\n",
    "df_train1 = df_train[inputs]\n",
    "\n",
    "print (df_train1.columns)\n",
    "print (df_train1.head())\n",
    "\n",
    "\n",
    "X = df_train1.drop('vinn',axis =1).values\n",
    "y = df_train1['vinn'].values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=128, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model to HDF5 format\n",
    "model.save(\"mlp_model.h5\")\n",
    "print(\"Model saved to disk.\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('VarScore:',metrics.explained_variance_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9035522-e8f9-4f0c-ac96-da963974fcf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da94ba-6a1e-469f-a634-b8a87e28b86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2e10f7-51a0-434e-957c-9cca48919429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedd6f79-1e66-4feb-ba42-bdb92b5035ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1efaf02-168c-4065-8a37-f3f2eea139f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebd19bf-3207-401b-84b6-33367cd92113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247bf1b-b814-4d72-b7d0-502bf56ddfa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e8b32-3aa1-46eb-8e58-47ced7f05064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
