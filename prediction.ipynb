{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e5d8486",
   "metadata": {},
   "source": [
    "## import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee578b2-c2d4-4f7f-b081-5b2528e937df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the model and label encoder from the pickle file\n",
    "with open('Random_forest_model.pkl', 'rb') as file:\n",
    "    model_data = pickle.load(file)\n",
    "\n",
    "\n",
    "loaded_model = model_data['model']\n",
    "loaded_encoder = model_data['label_encoder']\n",
    "feature_names = model_data['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14edb29-779d-4bed-bf51-4dd683371146",
   "metadata": {},
   "source": [
    "## .predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "811b1df3-111b-4864-b70e-28e557a8826a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted vinn: 0.5328154581304556\n",
      "   vdd   pd      vinp  temperature  process\n",
      "0  3.0  3.0  1.638227          -15        2\n"
     ]
    }
   ],
   "source": [
    "new_data = [[3.0000, 3.0000, 1.638227, -15, 'slownfastp']]\n",
    "\n",
    "new_df = pd.DataFrame(new_data, columns=['vdd', 'pd', 'vinp', 'temperature', 'process'])\n",
    "new_df['process'] = loaded_encoder.transform(new_df['process'])\n",
    "\n",
    "prediction = loaded_model.predict(new_df)\n",
    "\n",
    "print(f'Predicted vinn: {prediction[0]}')\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ecdc93-dda4-49fe-9176-6f887001295b",
   "metadata": {},
   "source": [
    "## manual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bda1146-8ec2-4215-87af-7c3d350a2804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77fcdbbe-b997-4c86-8641-b197225d1110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_predict(model, features):\n",
    "    predictions = []\n",
    "    for tree in model.estimators_:\n",
    "        tree_prediction = traverse_tree(tree.tree_, features)\n",
    "        predictions.append(tree_prediction)\n",
    "    return sum(predictions) / len(predictions)\n",
    "\n",
    "def traverse_tree(tree, features):\n",
    "    node_id = 0\n",
    "    while True:\n",
    "        feature = tree.feature[node_id]\n",
    "        if feature == -2:  # Leaf node\n",
    "            return tree.value[node_id][0][0]\n",
    "        else:\n",
    "            if features[feature] <= tree.threshold[node_id]:\n",
    "                next_node_id = tree.children_left[node_id]\n",
    "            else:\n",
    "                next_node_id = tree.children_right[node_id]\n",
    "            if next_node_id == -1:\n",
    "                return tree.value[node_id][0][0]\n",
    "            else:\n",
    "                node_id = next_node_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "603ccae8-c24e-4a0a-bb32-9f24ca2132bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   vdd   pd      vinp  temperature  process\n",
      "0  3.0  3.0  1.638227          -15        3\n",
      "Manual Prediction for input features: 0.7550352739242591\n"
     ]
    }
   ],
   "source": [
    "# Input data for prediction\n",
    "new_data = [[3.0000, 3.0000, 1.638227, -15, 'slownslowp']]\n",
    "new_df = pd.DataFrame(new_data, columns=['vdd', 'pd', 'vinp', 'temperature', 'process'])\n",
    "new_df['process'] = loaded_encoder.transform(new_df['process'])\n",
    "\n",
    "print(new_df)\n",
    "# Manual prediction\n",
    "manual_prediction = manual_predict(loaded_model, new_df.values[0])\n",
    "print(f\"Manual Prediction for input features: {manual_prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876343ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('Random_Forest.pkl', 'rb') as file:\n",
    "    model_data = pickle.load(file)\n",
    "\n",
    "\n",
    "\n",
    "loaded_model = model_data['model']\n",
    "loaded_encoder = model_data['label_encoder']\n",
    "feature_names = model_data['feature_names']\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "data = pd.read_csv(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\FourthSEM\\test\\fastnfastp_3.6V_45.csv\")\n",
    "time = data['time']\n",
    "vinn = data['vinn']\n",
    "\n",
    "plt.plot(time, vinn, label='Actual', color='b')\n",
    "\n",
    "new_data = data[['vdd', 'pd', 'vinp', 'temperature','process']]\n",
    "# new_data = loaded_encoder.transform(new_data['process'])\n",
    "new_df = pd.DataFrame(new_data, columns=['vdd', 'pd', 'vinp', 'temperature','process'])\n",
    "new_df['process'] = loaded_encoder.transform(new_df['process'])\n",
    "\n",
    "prediction = loaded_model.predict(new_df)\n",
    "\n",
    "print(f'Predicted vinn: {prediction[0]}')\n",
    "print(new_df)\n",
    "plt.plot(time, prediction, label='Predicted', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Output')\n",
    "plt.title('Waveform Plot Actual vs Predicted')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('Random_Forest_20.pkl', 'rb') as file:\n",
    "    model_data = pickle.load(file)\n",
    "\n",
    "\n",
    "\n",
    "loaded_model = model_data['model']\n",
    "loaded_encoder = model_data['label_encoder']\n",
    "feature_names = model_data['feature_names']\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "data = pd.read_csv(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\FourthSEM\\test\\fastnfastp_3.6V_45.csv\")\n",
    "time = data['time']\n",
    "vinn = data['vinn']\n",
    "\n",
    "plt.plot(time, vinn, label='Actual', color='b')\n",
    "\n",
    "new_data = data[['vdd', 'pd', 'vinp', 'temperature','process']]\n",
    "# new_data = loaded_encoder.transform(new_data['process'])\n",
    "new_df = pd.DataFrame(new_data, columns=['vdd', 'pd', 'vinp', 'temperature','process'])\n",
    "new_df['process'] = loaded_encoder.transform(new_df['process'])\n",
    "\n",
    "prediction = loaded_model.predict(new_df)\n",
    "\n",
    "print(f'Predicted vinn: {prediction[0]}')\n",
    "print(new_df)\n",
    "plt.plot(time, prediction, label='Predicted', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Output')\n",
    "plt.title('Waveform Plot Actual vs Predicted')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701529a1-1d37-494a-9da6-0f8dd4f3665c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc956238-401b-4a2a-8dad-0cfe15533e40",
   "metadata": {},
   "source": [
    "## if-else Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b6ca63-b281-48be-b19c-f350eea5bd22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import _tree\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def get_rules(tree, feature_names, class_names):\n",
    "    try:\n",
    "        tree_ = tree.tree_\n",
    "        feature_name = [\n",
    "            feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "            for i in tree_.feature\n",
    "        ]\n",
    "\n",
    "        paths = []\n",
    "        path = []\n",
    "\n",
    "        def recurse(node, path, paths):\n",
    "            if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "                name = feature_name[node]\n",
    "                threshold = tree_.threshold[node]\n",
    "                p1, p2 = list(path), list(path)\n",
    "                p1 += [f\"({name} <= {np.round(threshold, 3)})\"]\n",
    "                recurse(tree_.children_left[node], p1, paths)\n",
    "                p2 += [f\"({name} > {np.round(threshold, 3)})\"]\n",
    "                recurse(tree_.children_right[node], p2, paths)\n",
    "            else:\n",
    "                path += [(tree_.value[node], tree_.n_node_samples[node])]\n",
    "                paths += [path]\n",
    "\n",
    "        recurse(0, path, paths)\n",
    "\n",
    "        samples_count = [p[-1][1] for p in paths]\n",
    "        ii = list(np.argsort(samples_count))\n",
    "        paths = [paths[i] for i in reversed(ii)]\n",
    "\n",
    "        rules = []\n",
    "        for path in paths:\n",
    "            rule = \"if \"\n",
    "\n",
    "            for p in path[:-1]:\n",
    "                if rule != \"if \":\n",
    "                    rule += \" and \"\n",
    "                rule += str(p)\n",
    "            \n",
    "            if class_names is None:\n",
    "                rule += \": return \" + str(np.round(path[-1][0][0][0], 3))\n",
    "            else:\n",
    "                classes = path[-1][0][0]\n",
    "                l = np.argmax(classes)\n",
    "                rule += f\"class: {class_names[l]} (proba: {np.round(100.0 * classes[l] / np.sum(classes), 2)}%)\"\n",
    "\n",
    "            rules += [rule]\n",
    "\n",
    "        return rules\n",
    "    except (AttributeError, NameError) as e:\n",
    "        print(f\"Error extracting rules: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_all_rules(forest, feature_names, class_names):\n",
    "    all_rules = []\n",
    "    for tree in forest.estimators_:\n",
    "        rules = get_rules(tree, feature_names, class_names)\n",
    "        if rules:\n",
    "            all_rules.append(rules)\n",
    "    return all_rules\n",
    "\n",
    "\n",
    "\n",
    "# Load the model\n",
    "with open('Random_forest_model.pkl', 'rb') as file:\n",
    "    model_data = pickle.load(file)\n",
    "\n",
    "model = model_data['model']\n",
    "loaded_encoder = model_data['label_encoder']\n",
    "feature_names = model_data['feature_names']\n",
    "\n",
    "print(\"Random Forest Regressor model loaded successfully.\")\n",
    "    \n",
    "  \n",
    "class_names = None  \n",
    "\n",
    "# Extract rules from the Random Forest\n",
    "all_rules = get_all_rules(model, feature_names, class_names)\n",
    "\n",
    "# Print the extracted rules\n",
    "for i, tree_rules in enumerate(all_rules):\n",
    "    print(f\"\\nRules from Tree {i+1}\")\n",
    "    for rule in tree_rules:\n",
    "        print(rule)\n",
    "\n",
    "# Write rules to a file if needed\n",
    "with open('output.txt', 'w') as file:\n",
    "    for i, tree_rules in enumerate(all_rules):\n",
    "        file.write(f\"\\nRules from Tree {i+1}\\n\")\n",
    "        for rule in tree_rules:\n",
    "            file.write(rule + '\\n')\n",
    "\n",
    "print(\"Rules have been extracted and written to output.txt.\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd79e5f-8d40-4b2b-a484-254984cd0486",
   "metadata": {},
   "source": [
    "## Read Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6dce846-e7c3-4ee2-8dd5-43478588c024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'process', 'vdd', 'temperature', 'pd', 'vinp'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pickle\n",
    "\n",
    "def extract_words_after_parentheses(pseudocode):\n",
    "    \n",
    "    matches = re.findall(r'\\(\\s*([a-zA-Z]+)\\s*>', pseudocode)\n",
    "    \n",
    "    extracted_set = set(matches)\n",
    "    \n",
    "    return extracted_set\n",
    "\n",
    "def read_pseudocode_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        pseudocode = file.read()\n",
    "    return pseudocode\n",
    "\n",
    "file_path = \"output.txt\"\n",
    "pseudocode = read_pseudocode_from_file(file_path)\n",
    "\n",
    "result_set = extract_words_after_parentheses(pseudocode)\n",
    "\n",
    "print(result_set)\n",
    "\n",
    "\n",
    "\n",
    "def export_set(my_set, file_path):\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(my_set, file)\n",
    "\n",
    "export_file_path = 'exported_set.pkl'\n",
    "\n",
    "export_set(result_set, export_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0899f0a1-4ac4-45cc-96a1-7aafbd0aab95",
   "metadata": {},
   "source": [
    "## Generate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bb5c685-68cf-45bd-8d9b-57a22214831c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Set: {'process', 'vdd', 'temperature', 'pd', 'vinp'}\n",
      "Python Code generated\n",
      "Python code has been saved to: fun.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "def import_set(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        my_set = pickle.load(file)\n",
    "    return my_set\n",
    "\n",
    "import_file_path = 'exported_set.pkl'\n",
    "\n",
    "\n",
    "def generate_python_code_from_pseudocode(pseudocode_lines, input_parameters):\n",
    "    python_code = \"\"\n",
    "    rule_count = 1\n",
    "    capture_lines = False\n",
    "\n",
    "    for line in pseudocode_lines:\n",
    "        if f\"Rules from Tree {rule_count}\" in line:\n",
    "            parameter_string = ', '.join(f\"{param}=None\" for param in input_parameters)\n",
    "            python_code += f\"\\ndef decision_tree_rule_{rule_count}({parameter_string}):\" + \"\\n\"\n",
    "            rule_count += 1\n",
    "            capture_lines = True\n",
    "\n",
    "        elif capture_lines and line.strip():  \n",
    "            indented_code_block = \"    \" + line.replace('return', '\\n        return')\n",
    "            python_code += f\"{indented_code_block}\" + \"\\n\"\n",
    "\n",
    "    return python_code\n",
    "\n",
    "\n",
    "input_parameters = import_set(import_file_path)\n",
    "print(\"Imported Set:\", input_parameters)\n",
    "\n",
    "file_path = \"output.txt\" \n",
    "with open(file_path, 'r') as file:\n",
    "    pseudocode_lines = file.readlines()\n",
    "\n",
    "\n",
    "python_code = generate_python_code_from_pseudocode(pseudocode_lines, input_parameters)\n",
    "print(\"Python Code generated\")\n",
    "\n",
    "output_file_path = \"fun.py\"  \n",
    "with open(output_file_path, 'w') as code_file:\n",
    "    code_file.write(python_code)\n",
    "\n",
    "print(f\"Python code has been saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fdd4ac-d9cc-418e-8bd7-7309b76942b2",
   "metadata": {},
   "source": [
    "## predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799486d8-8f04-44a3-a030-31f0b2a08502",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def import_set(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        my_set = pickle.load(file)\n",
    "    return my_set\n",
    "\n",
    "import_file_path = 'exported_set.pkl'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_all_conditions(**kwargs):\n",
    "    results = []\n",
    "\n",
    "    function_file_path = \"fun.py\"\n",
    "\n",
    "    with open(function_file_path, 'r') as file:\n",
    "        functions_code = file.read()\n",
    "\n",
    "    for i in range(1,101):\n",
    "        function_name = f\"decision_tree_rule_{i}\"\n",
    "        exec(functions_code)\n",
    "        function = locals()[function_name]\n",
    "        result = function(**kwargs) or 0\n",
    "        results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "with open('Random_forest_model.pkl', 'rb') as file:\n",
    "    model_data = pickle.load(file)\n",
    "\n",
    "model = model_data['model']\n",
    "loaded_encoder = model_data['label_encoder']\n",
    "feature_names = model_data['feature_names']\n",
    "\n",
    "\n",
    "input_parameters = import_set(import_file_path)\n",
    "\n",
    "print(\"Imported Set:\", input_parameters)\n",
    "\n",
    "## input  values\n",
    "new_data = [[3.0000, 3.0000, 1.638227, 85, 'slownslowp']]\n",
    "new_df = pd.DataFrame(new_data, columns=['vdd', 'pd', 'vinp', 'temperature', 'process'])\n",
    "new_df['process'] = loaded_encoder.transform(new_df['process'])\n",
    "\n",
    "vinp_value = new_df['vinp'][0]\n",
    "pd_value = new_df['pd'][0]\n",
    "vdd_value = new_df['vdd'][0]\n",
    "process_value = new_df['process'][0]\n",
    "temperature_value =new_df['temperature'][0]\n",
    "\n",
    "\n",
    "input_values = {'vinp': vinp_value, 'pd': pd_value, 'vdd': vdd_value, 'process':process_value,'temperature':temperature_value}\n",
    "\n",
    "result_list = evaluate_all_conditions(**input_values)\n",
    "\n",
    "print(\"Length:\", len(result_list))\n",
    "print(\"Results:\", result_list)\n",
    "print(\"Average:\", np.average(result_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e81a20-1eea-401b-8bf6-c73b1a960be2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc23e84-01e0-451f-a9ce-761a4fd9bd46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import export_text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "def load_model(pkl_path):\n",
    "    try:\n",
    "        with open(pkl_path, 'rb') as file:\n",
    "            model_data = pickle.load(file)\n",
    "        return model_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "pkl_path = 'Random_forest_model.pkl'\n",
    "loaded_model_data = load_model(pkl_path)\n",
    "\n",
    "if loaded_model_data is not None and isinstance(loaded_model_data['model'], RandomForestRegressor):\n",
    "    print(\"RandomForestRegressor model loaded successfully.\")\n",
    "\n",
    "    loaded_model = loaded_model_data['model']\n",
    "    feature_names = loaded_model_data['feature_names']\n",
    "    \n",
    "    print(\"Original Feature Names:\", feature_names)\n",
    "\n",
    "    num_features = loaded_model.estimators_[0].tree_.n_features\n",
    "    print(\"Number of Features:\", num_features)\n",
    "    \n",
    "    # Define feature names if not available\n",
    "    feature_names = [f'Feature_{i}' for i in range(1, num_features + 1)]\n",
    "\n",
    "    for i, tree in enumerate(loaded_model.estimators_):\n",
    "        tree_text = export_text(tree, feature_names=feature_names)\n",
    "        print(f\"Decision Tree {i + 1}:\\n{tree_text}\\n{'='*50}\\n\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to load the RandomForestRegressor model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791fd451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Load the model and label encoder from the pickle file\n",
    "with open('Random_forest_model.pkl', 'rb') as file:\n",
    "    model_data = pickle.load(file)\n",
    "\n",
    "loaded_model = model_data['model']\n",
    "loaded_encoder = model_data['label_encoder']\n",
    "feature_names = model_data['feature_names']\n",
    "\n",
    "# Prepare new data\n",
    "new_data = [[3.0000, 3.0000, 1.638227, 85, 'slownfastp']]\n",
    "new_df = pd.DataFrame(new_data, columns=['vdd', 'pd', 'vinp', 'temperature', 'process'])\n",
    "\n",
    "# Transform categorical features using the loaded label encoder\n",
    "new_df['process'] = loaded_encoder.transform(new_df['process'])\n",
    "\n",
    "# Make the prediction\n",
    "prediction = loaded_model.predict(new_df[feature_names])\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_true, prediction)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, prediction))\n",
    "\n",
    "# Calculate Signal-to-Noise Ratio (SNR)\n",
    "signal_power = np.mean(y_true**2)\n",
    "noise_power = np.mean((y_true - prediction)**2)\n",
    "snr = 10 * np.log10(signal_power / noise_power)\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "print(f'Signal-to-Noise Ratio (SNR): {snr}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704a1c3e-3473-4599-9ca1-fce7eefe16e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('Random_forest_model.pkl', 'rb') as file:\n",
    "    model_data = pickle.load(file)\n",
    "\n",
    "loaded_model = model_data['model']\n",
    "loaded_encoder = model_data['label_encoder']\n",
    "feature_names = model_data['feature_names']\n",
    "\n",
    "\n",
    "folder_path = r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\FourthSEM\\test\"\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        csv_path = os.path.join(folder_path, filename)\n",
    "        csv_data = pd.read_csv(csv_path)\n",
    "        for index, row in csv_data.iterrows():\n",
    "            \n",
    "            input_data = np.array(row[['vdd','pd','vinp','temperature','process']]).reshape(1, -1) \n",
    "            new_df = pd.DataFrame(input_data, columns=['vdd', 'pd', 'vinp', 'temperature', 'process'])\n",
    "            new_df['process'] = loaded_encoder.transform(new_df['process'])\n",
    "            \n",
    "            input_data = new_df\n",
    "            prediction = loaded_model.predict(input_data)\n",
    "            print(f'Prediction for row {index} in file {filename}: {prediction[0]}')\n",
    "\n",
    "\n",
    "predictions = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        csv_path = os.path.join(folder_path, filename)\n",
    "        csv_data = pd.read_csv(csv_path)\n",
    "        for index, row in csv_data.iterrows():\n",
    "            input_data = np.array(row[['vdd','pd','vinp','temperature','process']]).reshape(1, -1)  \n",
    "            new_df = pd.DataFrame(input_data, columns=['vdd', 'pd', 'vinp', 'temperature', 'process'])\n",
    "            new_df['process'] = loaded_encoder.transform(new_df['process'])\n",
    "            \n",
    "            input_data = new_df\n",
    "            prediction = loaded_model.predict(input_data)\n",
    "            predictions.append(prediction[0])\n",
    "\n",
    "y_test = csv_data['vinn'] \n",
    "rmse = sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f'Root Mean Squared Error: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70aebe9-233d-40a8-ae34-7c2d6f72ad50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('Random_forest_model.pkl', 'rb') as file:\n",
    "    model_data = pickle.load(file)\n",
    "\n",
    "loaded_model = model_data['model']\n",
    "loaded_encoder = model_data['label_encoder']\n",
    "feature_names = model_data['feature_names']\n",
    "\n",
    "folder_path = r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\FourthSEM\\test\"\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        csv_path = os.path.join(folder_path, filename)\n",
    "        csv_data = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Extract specific columns for input and output waveforms\n",
    "        input_cols = ['vdd', 'pd', 'vinp', 'temperature','process']\n",
    "        output_col = 'vinn'\n",
    "        \n",
    "        for index, row in csv_data.iterrows():\n",
    "            # Extract input data\n",
    "            input_data = np.array(row[['vdd','pd','vinp','temperature','process']]).reshape(1, -1) \n",
    "            new_df = pd.DataFrame(input_data, columns=['vdd', 'pd', 'vinp', 'temperature', 'process'])\n",
    "            new_df['process'] = loaded_encoder.transform(new_df['process'])\n",
    "            input_data = new_df\n",
    "            # Predict\n",
    "            prediction = loaded_model.predict(input_data)\n",
    "            \n",
    "            # Print prediction\n",
    "            print(f'Prediction for row {index} in file {filename}: {prediction[0]}')\n",
    "            \n",
    "            # Plot input waveform\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(range(len(input_cols)), input_data[0], marker='o', label='Input Waveform')\n",
    "            plt.xticks(range(len(input_data)), input_cols)\n",
    "            plt.xlabel('Features')\n",
    "            plt.ylabel('Values')\n",
    "            plt.title('Input Waveform')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            # Plot output waveform (actual vs. predicted)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(row.index, row[output_col], label='Actual')\n",
    "            plt.plot(row.index, [prediction[0]] * len(row), label='Predicted')\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Voltage')\n",
    "            plt.title('Output Waveform (Actual vs. Predicted)')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "# Calculate RMSE\n",
    "y_test = csv_data[output_col] \n",
    "rmse = sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f'Root Mean Squared Error: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9499ce6-8ff6-4c48-be8b-1ac4a85683b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the model and label encoder from the pickle file\n",
    "with open('Random_forest_model.pkl', 'rb') as file:\n",
    "    model_data = pickle.load(file)\n",
    "\n",
    "loaded_model = model_data['model']\n",
    "loaded_encoder = model_data['label_encoder']\n",
    "feature_names = model_data['feature_names']\n",
    "\n",
    "# Define the folder path containing CSV files\n",
    "folder_path = r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\FourthSEM\\test\"\n",
    "\n",
    "# Lists to store predictions and actual values\n",
    "predictions = []\n",
    "actual_values = []\n",
    "\n",
    "# Iterate over each CSV file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        csv_path = os.path.join(folder_path, filename)\n",
    "        csv_data = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Iterate over each row in the CSV file\n",
    "        for index, row in csv_data.iterrows():\n",
    "            # Extract input features\n",
    "            input_data = np.array(row[['vdd', 'pd', 'vinp', 'temperature', 'process']]).reshape(1, -1)\n",
    "            # Transform categorical feature 'process' using loaded label encoder\n",
    "            input_data[0, -1] = loaded_encoder.transform([input_data[0, -1]])\n",
    "            \n",
    "            # Make prediction\n",
    "            prediction = loaded_model.predict(input_data)\n",
    "            predictions.append(prediction[0])\n",
    "            \n",
    "            # Print prediction for the row\n",
    "            print(f'Prediction for row {index} in file {filename}: {prediction[0]}')\n",
    "\n",
    "            # Plot input waveform\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(range(len(input_data.flatten())), input_data.flatten(), marker='o', label='Input Waveform')\n",
    "            plt.xlabel('Features')\n",
    "            plt.ylabel('Values')\n",
    "            plt.title('Input Waveform')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            # Plot output waveform (actual vs. predicted)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(range(len(row['vinn'])), row['vinn'], label='Actual')\n",
    "            plt.plot(range(len(row['vinn'])), [prediction[0]] * len(row['vinn']), label='Predicted')\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Voltage')\n",
    "            plt.title('Output Waveform (Actual vs. Predicted)')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            # Append actual and predicted values\n",
    "            actual_values.append(row['vinn'])\n",
    "            predictions.append(prediction[0])\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(actual_values, predictions))\n",
    "print(f'Root Mean Squared Error: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6304750f-b7b2-4202-ad75-c8c182afc9d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the model and label encoder from the pickle file\n",
    "with open('Random_forest_model.pkl', 'rb') as file:\n",
    "    model_data = pickle.load(file)\n",
    "\n",
    "loaded_model = model_data['model']\n",
    "loaded_encoder = model_data['label_encoder']\n",
    "feature_names = model_data['feature_names']\n",
    "\n",
    "# Define the folder path containing CSV files\n",
    "folder_path = r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\FourthSEM\\test\"\n",
    "\n",
    "# Lists to store predictions and actual values\n",
    "predictions = []\n",
    "actual_values = []\n",
    "\n",
    "# Iterate over each CSV file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        csv_path = os.path.join(folder_path, filename)\n",
    "        csv_data = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Iterate over each row in the CSV file\n",
    "        for index, row in csv_data.iterrows():\n",
    "            # Extract input features\n",
    "            input_data = np.array(row[['vdd', 'pd', 'vinp', 'temperature', 'process']]).reshape(1, -1)\n",
    "            # Transform categorical feature 'process' using loaded label encoder\n",
    "            input_data[0, -1] = loaded_encoder.transform([input_data[0, -1]])\n",
    "            \n",
    "            # Make prediction\n",
    "            prediction = loaded_model.predict(input_data)\n",
    "            predictions.append(prediction[0])\n",
    "            \n",
    "            # Print prediction for the row\n",
    "            print(f'Prediction for row {index} in file {filename}: {prediction[0]}')\n",
    "\n",
    "            # Plot input waveform\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(range(len(input_data.flatten())), input_data.flatten(), marker='o', label='Input Waveform')\n",
    "            plt.xlabel('Features')\n",
    "            plt.ylabel('Values')\n",
    "            plt.title('Input Waveform')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            # Plot output waveform (actual vs. predicted)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            actual_value = row['vinn']\n",
    "            if isinstance(actual_value, (list, np.ndarray)):\n",
    "                actual_values = actual_value\n",
    "            else:\n",
    "                actual_values = [actual_value]\n",
    "            plt.plot(range(len(actual_values)), actual_values, label='Actual')\n",
    "            plt.plot(range(len(actual_values)), [prediction[0]] * len(actual_values), label='Predicted')\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Voltage')\n",
    "            plt.title('Output Waveform (Actual vs. Predicted)')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            # Append actual and predicted values\n",
    "            predictions.append(prediction[0])\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(actual_values, predictions))\n",
    "print(f'Root Mean Squared Error: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91eb2a8-3fb9-463f-a3e8-8f475561c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Load the model and label encoder from the pickle file\n",
    "with open('Random_forest_model.pkl', 'rb') as file:\n",
    "    model_data = pickle.load(file)\n",
    "\n",
    "loaded_model = model_data['model']\n",
    "loaded_encoder = model_data['label_encoder']\n",
    "feature_names = model_data['feature_names']\n",
    "\n",
    "# Define the folder path containing CSV files\n",
    "folder_path = r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\FourthSEM\\test\"\n",
    "\n",
    "# Create a figure and axis for the waveform plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Initialize empty lists to store predictions and actual values\n",
    "predictions = []\n",
    "actual_values = []\n",
    "\n",
    "# Define a function to update the plot\n",
    "def update_plot(frame):\n",
    "    ax.clear()  # Clear the axis for new plot\n",
    "    \n",
    "    # Read the CSV file for the current frame\n",
    "    filename = os.listdir(folder_path)[frame]\n",
    "    csv_path = os.path.join(folder_path, filename)\n",
    "    csv_data = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Iterate over each row in the CSV file\n",
    "    for index, row in csv_data.iterrows():\n",
    "        # Extract input features\n",
    "        input_data = np.array(row[['vdd', 'pd', 'vinp', 'temperature', 'process']]).reshape(1, -1)\n",
    "        # Transform categorical feature 'process' using loaded label encoder\n",
    "        input_data[0, -1] = loaded_encoder.transform([input_data[0, -1]])\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = loaded_model.predict(input_data)\n",
    "        predictions.append(prediction[0])\n",
    "        \n",
    "        # Print prediction for the row\n",
    "        print(f'Prediction for row {index} in file {filename}: {prediction[0]}')\n",
    "\n",
    "        # Plot input waveform\n",
    "        ax.plot(range(len(input_data.flatten())), input_data.flatten(), marker='o', label='Input Waveform')\n",
    "        \n",
    "        # Append actual value\n",
    "        actual_values.append(row['vinn'])\n",
    "        \n",
    "        # Plot output waveform (actual vs. predicted)\n",
    "        ax.plot(range(len(actual_values)), actual_values, label='Actual')\n",
    "        ax.plot(range(len(predictions)), predictions, label='Predicted')\n",
    "        \n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('Voltage')\n",
    "        ax.set_title('Output Waveform (Actual vs. Predicted)')\n",
    "        ax.legend()\n",
    "\n",
    "# Create an animation\n",
    "animation = FuncAnimation(fig, update_plot, frames=len(os.listdir(folder_path)), repeat=False)\n",
    "\n",
    "# Show the animation\n",
    "plt.show()\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(actual_values, predictions))\n",
    "print(f'Root Mean Squared Error: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c014eb9-ef35-465a-8153-20689179ad39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
