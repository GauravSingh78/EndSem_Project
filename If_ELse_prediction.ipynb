{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 4.02 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# import pickle\n",
    "with open(\"Random_Forest_20.pkl\",'rb') as file:\n",
    "    m = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = m['model']\n",
    "feature_names = m['feature_names']\n",
    "label_encoder = m['label_encoder']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rules have been extracted and written to output.txt\n",
      "CPU times: total: 906 ms\n",
      "Wall time: 5.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import _tree\n",
    "import numpy as np\n",
    "\n",
    "def get_rules(tree, feature_names, class_names):\n",
    "    try:\n",
    "        tree_ = tree.tree_\n",
    "        feature_name = [\n",
    "            feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "            for i in tree_.feature\n",
    "        ]\n",
    "\n",
    "        paths = []\n",
    "        path = []\n",
    "\n",
    "        def recurse(node, path, paths):\n",
    "            if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "                name = feature_name[node]\n",
    "                threshold = tree_.threshold[node]\n",
    "                p1, p2 = list(path), list(path)\n",
    "                p1 += [f\"({name} <= {np.round(threshold, 3)})\"]\n",
    "                recurse(tree_.children_left[node], p1, paths)\n",
    "                p2 += [f\"({name} > {np.round(threshold, 3)})\"]\n",
    "                recurse(tree_.children_right[node], p2, paths)\n",
    "            else:\n",
    "                path += [(tree_.value[node], tree_.n_node_samples[node])]\n",
    "                paths += [path]\n",
    "\n",
    "        recurse(0, path, paths)\n",
    "\n",
    "        samples_count = [p[-1][1] for p in paths]\n",
    "        ii = list(np.argsort(samples_count))\n",
    "        paths = [paths[i] for i in reversed(ii)]\n",
    "\n",
    "        rules = []\n",
    "        for path in paths:\n",
    "            rule = \"if \"\n",
    "\n",
    "            for p in path[:-1]:\n",
    "                if rule != \"if \":\n",
    "                    rule += \" and \"\n",
    "                rule += str(p)\n",
    "            \n",
    "            if class_names is None:\n",
    "                rule += \": return \" + str(np.round(path[-1][0][0][0], 3))\n",
    "            else:\n",
    "                classes = path[-1][0][0]\n",
    "                l = np.argmax(classes)\n",
    "                rule += f\"class: {class_names[l]} (proba: {np.round(100.0 * classes[l] / np.sum(classes), 2)}%)\"\n",
    "\n",
    "            rules += [rule]\n",
    "\n",
    "        return rules\n",
    "    except (AttributeError, NameError) as e:\n",
    "        print(f\"Error extracting rules: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_all_rules(forest, feature_names, class_names):\n",
    "    all_rules = []\n",
    "    for tree in forest.estimators_:\n",
    "        rules = get_rules(tree, feature_names, class_names)\n",
    "        if rules:\n",
    "            all_rules.append(rules)\n",
    "    return all_rules\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "class_names = None  \n",
    "\n",
    "# Extract rules from the Random Forest\n",
    "all_rules = get_all_rules(model, feature_names, class_names)\n",
    "\n",
    "# Print the extracted rules\n",
    "# for i, tree_rules in enumerate(all_rules):\n",
    "#     print(f\"\\nRules from Tree {i+1}\")\n",
    "#     for rule in tree_rules:\n",
    "#         print(rule)\n",
    "\n",
    "# Write rules to a file if needed\n",
    "with open('output.txt', 'w') as file:\n",
    "    for i, tree_rules in enumerate(all_rules):\n",
    "        file.write(f\"\\nRules from Tree {i+1}\\n\")\n",
    "        for rule in tree_rules:\n",
    "            file.write(rule + '\\n')\n",
    "\n",
    "print(\"Rules have been extracted and written to\",file.name)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vinp', 'pd', 'vdd', 'temperature', 'process'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pickle\n",
    "\n",
    "def extract_words_after_parentheses(pseudocode):\n",
    "    \n",
    "    matches = re.findall(r'\\(\\s*([a-zA-Z]+)\\s*>', pseudocode)\n",
    "    \n",
    "    extracted_set = set(matches)\n",
    "    \n",
    "    return extracted_set\n",
    "\n",
    "def read_pseudocode_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        pseudocode = file.read()\n",
    "    return pseudocode\n",
    "\n",
    "file_path = \"output.txt\"\n",
    "pseudocode = read_pseudocode_from_file(file_path)\n",
    "\n",
    "result_set = extract_words_after_parentheses(pseudocode)\n",
    "\n",
    "print(result_set)\n",
    "\n",
    "\n",
    "\n",
    "def export_set(my_set, file_path):\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(my_set, file)\n",
    "\n",
    "export_file_path = 'exported_set.pkl'\n",
    "\n",
    "export_set(result_set, export_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Set: {'vinp', 'pd', 'vdd', 'temperature', 'process'}\n",
      "Python Code generated\n",
      "Python code has been saved to: TreeFunction.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "def import_set(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        my_set = pickle.load(file)\n",
    "    return my_set\n",
    "\n",
    "import_file_path = 'exported_set.pkl'\n",
    "\n",
    "\n",
    "def generate_python_code_from_pseudocode(pseudocode_lines, input_parameters):\n",
    "    python_code = \"\"\n",
    "    rule_count = 1\n",
    "    capture_lines = False\n",
    "\n",
    "    for line in pseudocode_lines:\n",
    "        if f\"Rules from Tree {rule_count}\" in line:\n",
    "            parameter_string = ', '.join(f\"{param}=None\" for param in input_parameters)\n",
    "            python_code += f\"\\ndef decision_tree_rule_{rule_count}({parameter_string}):\" + \"\\n\"\n",
    "            rule_count += 1\n",
    "            capture_lines = True\n",
    "\n",
    "        elif capture_lines and line.strip():  \n",
    "            indented_code_block = \"    \" + line.replace('return', '\\n        return')\n",
    "            python_code += f\"{indented_code_block}\" + \"\\n\"\n",
    "\n",
    "    return python_code\n",
    "\n",
    "\n",
    "input_parameters = import_set(import_file_path)\n",
    "print(\"Imported Set:\", input_parameters)\n",
    "\n",
    "file_path = \"output.txt\" \n",
    "with open(file_path, 'r') as file:\n",
    "    pseudocode_lines = file.readlines()\n",
    "\n",
    "\n",
    "python_code = generate_python_code_from_pseudocode(pseudocode_lines, input_parameters)\n",
    "print(\"Python Code generated\")\n",
    "\n",
    "output_file_path = \"TreeFunction.py\"  \n",
    "with open(output_file_path, 'w') as code_file:\n",
    "    code_file.write(python_code)\n",
    "\n",
    "print(f\"Python code has been saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Set: {'vinp', 'pd', 'vdd', 'temperature', 'process'}\n",
      "Length: 20\n",
      "Prediction: 0.76765\n",
      "CPU times: total: 22.1 s\n",
      "Wall time: 22.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def import_set(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        my_set = pickle.load(file)\n",
    "    return my_set\n",
    "\n",
    "import_file_path = 'exported_set.pkl'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_all_conditions(**kwargs):\n",
    "    results = []\n",
    "\n",
    "    function_file_path = \"TreeFunction.py\"\n",
    "\n",
    "    with open(function_file_path, 'r') as file:\n",
    "        functions_code = file.read()\n",
    "\n",
    "    for i in range(1,21):\n",
    "        function_name = f\"decision_tree_rule_{i}\"\n",
    "        exec(functions_code)\n",
    "        function = locals()[function_name]\n",
    "        result = function(**kwargs) or 0\n",
    "        results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "with open('Random_Forest_20.pkl','rb') as f:\n",
    "    m = pickle.load(f)\n",
    "\n",
    "model = m['model']\n",
    "feature_names = m['feature_names']\n",
    "label_encoder = m['label_encoder']\n",
    "\n",
    "input_parameters = import_set(import_file_path)\n",
    "\n",
    "print(\"Imported Set:\", input_parameters)\n",
    "\n",
    "## input  values\n",
    "new_data = [[3.0000, 3.0000, 1.638227, 85, 'slownslowp']]\n",
    "new_df = pd.DataFrame(new_data, columns=['vdd', 'pd', 'vinp', 'temperature', 'process'])\n",
    "new_df['process'] = label_encoder.transform(new_df['process'])\n",
    "\n",
    "vinp_value = new_df['vinp'][0]\n",
    "pd_value = new_df['pd'][0]\n",
    "vdd_value = new_df['vdd'][0]\n",
    "process_value = new_df['process'][0]\n",
    "temperature_value =new_df['temperature'][0]\n",
    "\n",
    "\n",
    "input_values = {'vinp': vinp_value, 'pd': pd_value, 'vdd': vdd_value, 'process':process_value,'temperature':temperature_value}\n",
    "\n",
    "result_list = evaluate_all_conditions(**input_values)\n",
    "\n",
    "print(\"Length:\", len(result_list))\n",
    "# print(\"Results:\", result_list)\n",
    "print(\"Prediction:\", np.average(result_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:121\u001b[0m\n",
      "File \u001b[1;32m<timed exec>:23\u001b[0m, in \u001b[0;36mevaluate_all_conditions\u001b[1;34m(**kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from itertools import count\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def import_set(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        my_set = pickle.load(file)\n",
    "    return my_set\n",
    "\n",
    "def evaluate_all_conditions(**kwargs):\n",
    "    results = []\n",
    "\n",
    "    function_file_path = r\"TreeFunction.py\"\n",
    "\n",
    "    with open(function_file_path, 'r') as file:\n",
    "        functions_code = file.read()\n",
    "\n",
    "    for i in range(1, 21):\n",
    "        function_name = f\"decision_tree_rule_{i}\"\n",
    "        exec(functions_code)\n",
    "        function = locals()[function_name]\n",
    "        result = function(**kwargs) or 0\n",
    "        results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\Admin\\Desktop\\forthSem\\test\\fastnfastp_3.6V_45.csv\")\n",
    "\n",
    "x_data_input = []\n",
    "pdd = []\n",
    "vdd = []\n",
    "vinp = []\n",
    "temperature = []\n",
    "process = []\n",
    "\n",
    "index = count()\n",
    "\n",
    "def calculate_metrics(y_data, vinn):\n",
    "    rmse = np.sqrt(((y_data - vinn) ** 2).mean())\n",
    "    mae = np.abs(y_data - vinn).mean()\n",
    "    noise = y_data - vinn\n",
    "    signal_power = np.mean(y_data ** 2)\n",
    "    noise_power = np.mean(noise ** 2)\n",
    "    snr = 10 * np.log10(signal_power / noise_power)\n",
    "    return rmse, mae, snr\n",
    "\n",
    "def animate_input(i):\n",
    "    if next(index) < len(data):\n",
    "        x = data['time'].iloc[next(index)]\n",
    "        p = data['pd'].iloc[next(index)]\n",
    "        vin = data['vinp'].iloc[next(index)]\n",
    "        vd = data['vdd'].iloc[next(index)]\n",
    "        temp = data['temperature'].iloc[next(index)]\n",
    "        pro = data['process'].iloc[next(index)]\n",
    "\n",
    "        x_data_input.append(x)\n",
    "        pdd.append(p)\n",
    "        vinp.append(vin)\n",
    "        vdd.append(vd)\n",
    "        temperature.append(temp)\n",
    "        process.append(pro)\n",
    "        \n",
    "        ax1.clear()\n",
    "        ax1.plot(x_data_input, pdd, label='pdd')\n",
    "        ax1.plot(x_data_input, vinp, label='vinp')\n",
    "        ax1.plot(x_data_input, vdd, label='vdd')\n",
    "        ax1.plot(x_data_input, temperature, label='temperature')\n",
    "        ax1.plot(x_data_input, process, label='process')\n",
    "        ax1.set_xlabel('Time')\n",
    "        ax1.set_ylabel('Voltage')\n",
    "        ax1.set_title('Real-time Waveform Plot (Input)')\n",
    "        ax1.legend()\n",
    "\n",
    "x_data_output = []\n",
    "y_data = []\n",
    "vinn = []\n",
    "rmse_values = []\n",
    "mae_values = []\n",
    "snr_values = []\n",
    "\n",
    "def animate_output(i):\n",
    "    if next(index) < len(data):\n",
    "        x = data['time'].iloc[next(index)]\n",
    "        y = data['vinn'].iloc[next(index)]\n",
    "        vin = prediction[next(index)]\n",
    "        \n",
    "        x_data_output.append(x)\n",
    "        y_data.append(y)\n",
    "        vinn.append(vin)\n",
    "        \n",
    "        rmse, mae, snr = calculate_metrics(np.array(y_data), np.array(vinn))\n",
    "        rmse_values.append(rmse)\n",
    "        mae_values.append(mae)\n",
    "        snr_values.append(snr)\n",
    "        \n",
    "        ax2.clear()\n",
    "        ax2.plot(x_data_output, y_data, label='Actual', color='b')\n",
    "        ax2.plot(x_data_output, vinn, label='Predicted', color='red')\n",
    "        ax2.set_xlabel('Time')\n",
    "        ax2.set_ylabel('Voltage')\n",
    "        ax2.set_title('Real-time Waveform Plot (Output) \\n(RMSE: {:.4f}, MAE: {:.4f}, SNR: {:.4f})'.format(rmse, mae, snr))\n",
    "        ax2.legend()\n",
    "\n",
    "with open('Random_Forest_20.pkl', 'rb') as file:\n",
    "    model_data = pickle.load(file)\n",
    " \n",
    "loaded_model = model_data['model']\n",
    "feature_names = model_data['feature_names']\n",
    "label_encoder = model_data['label_encoder']\n",
    "\n",
    "new_data = data[['vdd', 'pd', 'vinp', 'temperature','process']]\n",
    "new_df = pd.DataFrame(new_data, columns=['vdd', 'pd', 'vinp', 'temperature','process'])\n",
    "new_df['process'] = label_encoder.transform(new_df['process'])\n",
    "prediction = []\n",
    "\n",
    "for index, row in new_df.iterrows():\n",
    "    input_values = row.to_dict()  \n",
    "    result_list = evaluate_all_conditions(**input_values)\n",
    "    prediction.append(result_list)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,10))\n",
    "ax1.set_title('Title 1', pad=20)  \n",
    "ax2.set_title('Title 2', pad=20)\n",
    "ax1.set_xlabel('X-axis label', labelpad=10) \n",
    "ax1.set_ylabel('Y-axis label', labelpad=10) \n",
    "ax2.set_xlabel('X-axis label', labelpad=10) \n",
    "ax2.set_ylabel('Y-axis label', labelpad=10)\n",
    "\n",
    "ani_input = FuncAnimation(fig, animate_input, interval=50, cache_frame_data=False)\n",
    "ani_output = FuncAnimation(fig, animate_output, interval=50, cache_frame_data=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Graphs plotted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
